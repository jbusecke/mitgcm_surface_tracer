{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Variance Budget for Busecke and Abernathey 2017\n",
    "\n",
    "In this notebook I evaluate the full tracer variance budget for all runs assembled for the 2017 ENSO diffusivity paper.\n",
    "\n",
    "The full budget (from Abernathey and Marshall 2013) can be written as:\n",
    "\n",
    "$$ \n",
    "\\underbrace{\\frac{\\partial}{\\partial t}\\frac{\\overline{{q^\\prime}^2}}{2}}\n",
    "_\\text{tendency} + \n",
    "\\underbrace{\\nabla \\cdot \\overline{v \\frac{{q^\\prime}^2}{2}}}\n",
    "_\\text{advection}+ \n",
    "\\underbrace{\\overline{v^\\prime q^\\prime} \\cdot \\nabla \\overline{q}}\n",
    "_\\text{production}=\n",
    "\\underbrace{\\nabla^2 \\left({\\kappa \\overline{ \\frac{{q^\\prime}^2}{2}}}\\right)}\n",
    "_\\text{diffusion} - \n",
    "\\underbrace{\\kappa \\overline{|{\\nabla q^\\prime}|^2}}\n",
    "_\\text{destruction}$$\n",
    "\n",
    "I do have the following \n",
    "\n",
    "% For the paper: \\usepackage{amsmath} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following terms are put out as diagnostics from the model:\n",
    "\n",
    "- $$\\overline{q}$$\n",
    "- $$\\overline{q^2}$$\n",
    "- $$\n",
    "\n",
    "The terms are calculated as follows:\n",
    "\n",
    "Production: \n",
    "$$\n",
    "\\overline{v^\\prime q^\\prime} \\cdot \\nabla \\overline{q} =\n",
    "\\overline{u^\\prime q^\\prime} \\frac{\\partial \\overline{q}}{\\partial x} +\n",
    "\\overline{v^\\prime q^\\prime} \\frac{\\partial \\overline{q}}{\\partial y} = \n",
    "(\\overline{uq} - \\overline{u} \\, \\overline{q}) \\frac{\\partial \\overline{q}}{\\partial x} +\n",
    "(\\overline{vq} - \\overline{v} \\, \\overline{q}) \\frac{\\partial \\overline{q}}{\\partial y}\n",
    "$$\n",
    "\n",
    "Advection:\n",
    "$$\n",
    "\\nabla = \\overline{ \\vec{u} \\frac{{q^\\prime}^2}{2}} = \n",
    "\\frac{\\partial}{\\partial x} \\overline{u \\frac{{q^\\prime}^2}{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.43.5.41:8786\n",
       "  <li><b>Dashboard: </b><a href='http://10.43.5.41:8787' target='_blank'>http://10.43.5.41:8787</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>41</li>\n",
       "  <li><b>Cores: </b>164</li>\n",
       "  <li><b>Memory: </b>492.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.43.5.41:8786' processes=41 cores=164>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client=Client(scheduler_file='/rigel/home/jb3210/scheduler.json')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from xmitgcm import open_mdsdataset\n",
    "from xgcm import Grid\n",
    "from os.path import join as pjoin\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic vector algebra (This should update the aviso tracer repo)\n",
    "def _get_matching(da, da_list):\n",
    "    \"\"\"from a list of xarray data arrays (da_list) return the one with dims \n",
    "    matching obj\"\"\"\n",
    "    matched = [a for a in da_list if set(a.dims).issubset(set(da.dims))]\n",
    "    if len(matched) == 0:\n",
    "        raise RuntimeError('no matching coordinates found. Try interpolating them using xgcm')\n",
    "    elif len(matched) >1 :\n",
    "        raise RuntimeError('More than one matching coord found, check list of data arrays')\n",
    "    else:\n",
    "        matched = matched[0]\n",
    "    return matched\n",
    "\n",
    "def _get_dx(da, grid_ds):\n",
    "    \"\"\"get horizontal distance\"\"\"\n",
    "    dx_list = [grid_ds[a] for a in ['dxC', 'dxG']]\n",
    "    return _get_matching(da,dx_list)\n",
    "\n",
    "def _get_dy(da, grid_ds):\n",
    "    \"\"\"get horizontal distance\"\"\"\n",
    "    dy_list = [grid_ds[a] for a in ['dyC', 'dyG']]\n",
    "    return _get_matching(da,dy_list)\n",
    "\n",
    "def _get_hfac(da, grid_ds):\n",
    "    \"\"\"get horizontal distance\"\"\"\n",
    "    hfac_list = [grid_ds[a] for a in ['hFacC', 'hFacW', 'hFacS']]\n",
    "    return _get_matching(da,hfac_list)\n",
    "    \n",
    "def _get_area(da, grid_ds):\n",
    "    area_list = [grid_ds[a] for a in ['rA', 'rAw', 'rAs']]\n",
    "    return _get_matching(da,area_list)\n",
    "\n",
    "def gradient(da, grid):\n",
    "    delta_x = grid.diff(da, 'X')\n",
    "    delta_y = grid.diff(da, 'Y')\n",
    "    dx = _get_dx(delta_x,grid._ds)\n",
    "    dy = _get_dy(delta_y,grid._ds)\n",
    "    da_dx = delta_x/dx\n",
    "    da_dy = delta_y/dy\n",
    "    return da_dx, da_dy\n",
    "\n",
    "def dot_prod(u1, v1, u2, v2, grid, ref):\n",
    "    u = u1*u2\n",
    "    v = v1*v2\n",
    "    \n",
    "    dyu = _get_dy(u, grid._ds)\n",
    "    dxv = _get_dx(v, grid._ds)\n",
    "    hfacu = _get_hfac(u, grid._ds)\n",
    "    hfacv = _get_hfac(v, grid._ds)\n",
    "    \n",
    "    u_int = u*dyu*hfacu\n",
    "    v_int = v*dxv*hfacv\n",
    "    dot_prod_int = xr.DataArray(u_int.data+v_int.data,\n",
    "                                coords=ref.coords, dims=ref.dims)\n",
    "    area = _get_area(dot_prod_int, grid._ds)\n",
    "    hfac = _get_hfac(dot_prod_int, grid._ds)\n",
    "    return dot_prod_int/area/hfac\n",
    "    \n",
    "\n",
    "def divergence(u, v, grid):\n",
    "    dyu = _get_dy(u, grid._ds)\n",
    "    dxv = _get_dx(v, grid._ds)\n",
    "    hfacu = _get_hfac(u, grid._ds)\n",
    "    hfacv = _get_hfac(v, grid._ds)\n",
    "    delta_u = grid.diff(u*dyu*hfacu, 'X')\n",
    "    delta_v = grid.diff(v*dxv*hfacv, 'Y')\n",
    "    area = _get_area(delta_u, grid._ds)\n",
    "    hfac = _get_hfac(delta_u, grid._ds)\n",
    "    return (delta_u+delta_v)/area/hfac\n",
    "\n",
    "def laplacian(da, grid):\n",
    "    gradx, grady = gradient(da, grid)\n",
    "    return divergence(gradx, grady, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # What am I doing wrong with the divergence?\n",
    "# test_u = ds_vel['UVEL'].isel(time=45)\n",
    "# test_v = ds_vel['VVEL'].isel(time=45)\n",
    "\n",
    "# test_dx_u = grid.interp(grid.diff(test_u, 'X'), 'X')\n",
    "# test_dy_v = grid.interp(grid.diff(test_v, 'Y'), 'Y')\n",
    "# test_div_alt = grid.interp(test_dx_u/_get_dx(test_dx_u, grid._ds), 'X') + \\\n",
    "#                     grid.interp(test_dy_v/_get_dy(test_dy_v, grid._ds), 'Y')\n",
    "# test_div = divergence(test_u,test_v, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# test_div.plot(vmin=-5e-8, vmax=5e-8, cmap=plt.cm.RdBu_r)\n",
    "# plt.figure()\n",
    "# test_div_alt.plot(vmin=-5e-8, vmax=5e-8, cmap=plt.cm.RdBu_r)\n",
    "\n",
    "# # plt.figure()\n",
    "# # test_div/test_div_alt.plot(robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This could potentially be integrated in xmitgcm\n",
    "def convert_trnum2dimension(ds):\n",
    "    def drop_nonmatching_vars(ds, var_list):\n",
    "        data_vars = list(ds.data_vars)\n",
    "        drop_vars = [a for a in data_vars if a not in var_list]\n",
    "        return ds.drop(drop_vars)\n",
    "    \n",
    "    def rename_vars(ds):\n",
    "        for vv in list(ds.data_vars):\n",
    "            ds = ds.rename({vv:vv[0:-2]})\n",
    "        return ds\n",
    "        \n",
    "    tr_num = list(set([a[-2:] for a in list(ds.data_vars)]))\n",
    "    tr_num.sort()\n",
    "    tr_vars = list(set([a[:-2] for a in list(ds.data_vars)]))\n",
    "    \n",
    "    datasets = [drop_nonmatching_vars(ds, [a+n for a in tr_vars]) for n in tr_num]\n",
    "    datasets = [rename_vars(b) for b in datasets]\n",
    "    \n",
    "    tr_num_int = [int(a) for a in tr_num]\n",
    "    \n",
    "    tr_dim = xr.DataArray(tr_num_int, \n",
    "                          dims='tracer_no',\n",
    "                          coords={'tracer_no': (['tracer_no', ], tr_num_int)})\n",
    "    \n",
    "    ds_combined = xr.concat(datasets,dim='tracer_no')\n",
    "    ds_combined['tracer_no'] = tr_dim\n",
    "    \n",
    "    return ds_combined\n",
    "\n",
    "# These should all go to the final version of the github repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddir = '/rigel/ocp/users/jb3210/projects/aviso_surface_tracer/runs'\n",
    "\n",
    "run = 'run_KOC_PSI_variance_budget'\n",
    "rundir = pjoin(ddir,run)\n",
    "timestep = 900 # in seconds\n",
    "readin_dict = dict(delta_t=timestep, swap_dims=False)\n",
    "kappa = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rigel/home/jb3210/src/xmitgcm/xmitgcm/utils.py:314: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n",
      "/rigel/home/jb3210/src/xmitgcm/xmitgcm/mds_store.py:220: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n"
     ]
    }
   ],
   "source": [
    "ds_mean = convert_trnum2dimension(open_mdsdataset(rundir,prefix=['tracer_diags'],\n",
    "                                                  **readin_dict))\n",
    "variance_mean = (ds_mean['TRACSQ']-(ds_mean['TRAC']**2))/2\n",
    "# ds_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rigel/home/jb3210/src/xmitgcm/xmitgcm/utils.py:314: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n",
      "/rigel/home/jb3210/src/xmitgcm/xmitgcm/mds_store.py:220: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n"
     ]
    }
   ],
   "source": [
    "readin_dict = dict(delta_t=timestep, swap_dims=False)\n",
    "ds_snap = convert_trnum2dimension(open_mdsdataset(rundir,prefix=['tracer_snapshots'],\n",
    "                                                  **readin_dict))\n",
    "variance_snap = (ds_snap['TRACSQ']-(ds_snap['TRAC']**2))/2\n",
    "# ds_snap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rigel/home/jb3210/src/xmitgcm/xmitgcm/utils.py:314: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n",
      "/rigel/home/jb3210/src/xmitgcm/xmitgcm/mds_store.py:220: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n"
     ]
    }
   ],
   "source": [
    "readin_dict = dict(delta_t=timestep, swap_dims=False)\n",
    "ds_vel = open_mdsdataset(rundir,prefix=['vel_diags'], **readin_dict)\n",
    "# ds_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgcm grid\n",
    "grid = Grid(ds_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (tracer_no: 2, time: 292, j: 1600, i: 3600)>\n",
       "dask.array<shape=(2, 292, 1600, 3600), dtype=float32, chunksize=(1, 1, 1600, 3600)>\n",
       "Coordinates:\n",
       "  * tracer_no  (tracer_no) int64 1 2\n",
       "  * i          (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "  * j          (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "    XC         (j, i) float32 0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 ...\n",
       "    YC         (j, i) float32 -79.95 -79.95 -79.95 -79.95 -79.95 -79.95 ...\n",
       "    rA         (j, i) float32 2.15699e+07 2.15699e+07 2.15699e+07 ...\n",
       "    Depth      (j, i) float32 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
       "    hFacC      (j, i) float32 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
       "    iter       (time) int64 2880 5760 8640 11520 14400 17280 20160 23040 ...\n",
       "  * time       (time) int64 2592000 5184000 7776000 10368000 12960000 ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Variance Destruction\n",
    "q_mean_gradx, q_mean_grady = gradient(ds_mean['TRAC'], grid)\n",
    "destruction_x = ds_mean['DXSqTr']-(q_mean_gradx**2)\n",
    "destruction_y = ds_mean['DYSqTr']-(q_mean_grady**2)\n",
    "destruction = -kappa*dot_prod(destruction_x, destruction_y, 1, 1, grid, ds_mean['TRAC'])\n",
    "destruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (tracer_no: 2, time: 292, j: 1600, i: 3600)>\n",
       "dask.array<shape=(2, 292, 1600, 3600), dtype=float32, chunksize=(1, 1, 1600, 3600)>\n",
       "Coordinates:\n",
       "  * tracer_no  (tracer_no) int64 1 2\n",
       "  * time       (time) int64 2592000 5184000 7776000 10368000 12960000 ...\n",
       "  * j          (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "  * i          (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "    XC         (j, i) float32 0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 ...\n",
       "    YC         (j, i) float32 -79.95 -79.95 -79.95 -79.95 -79.95 -79.95 ...\n",
       "    rA         (j, i) float32 2.15699e+07 2.15699e+07 2.15699e+07 ...\n",
       "    Depth      (j, i) float32 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
       "    hFacC      (j, i) float32 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Variance advection\n",
    "q_on_u = grid.interp(ds_mean['TRAC'], 'X')\n",
    "q_on_v = grid.interp(ds_mean['TRAC'], 'Y')\n",
    "u = ds_vel['UVEL']\n",
    "v = ds_vel['VVEL']\n",
    "uq = ds_mean['UTRAC']\n",
    "vq = ds_mean['VTRAC']\n",
    "uq_sq = ds_mean['UTrSq']\n",
    "vq_sq = ds_mean['VTrSq']\n",
    "\n",
    "u_q_pr_sq_mean = uq_sq - (uq*q_on_u) - (2*u*q_on_u**2)\n",
    "v_q_pr_sq_mean = vq_sq - (vq*q_on_v) - (2*v*q_on_v**2)\n",
    "advection = -divergence(u_q_pr_sq_mean, v_q_pr_sq_mean, grid)\n",
    "advection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (tracer_no: 2, time: 292, j: 1600, i: 3600)>\n",
       "dask.array<shape=(2, 292, 1600, 3600), dtype=float32, chunksize=(1, 1, 1600, 3600)>\n",
       "Coordinates:\n",
       "  * tracer_no  (tracer_no) int64 1 2\n",
       "  * i          (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "  * j          (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "    XC         (j, i) float32 0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 ...\n",
       "    YC         (j, i) float32 -79.95 -79.95 -79.95 -79.95 -79.95 -79.95 ...\n",
       "    rA         (j, i) float32 2.15699e+07 2.15699e+07 2.15699e+07 ...\n",
       "    Depth      (j, i) float32 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
       "    hFacC      (j, i) float32 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
       "    iter       (time) int64 2880 5760 8640 11520 14400 17280 20160 23040 ...\n",
       "  * time       (time) int64 2592000 5184000 7776000 10368000 12960000 ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance production\n",
    "q_mean_gradx, q_mean_grady = gradient(ds_mean['TRAC'], grid)\n",
    "q_pr_u_pr = (ds_mean['UTRAC']-(grid.interp(ds_mean['TRAC'],'X')*ds_vel['UVEL']))\n",
    "q_pr_v_pr = (ds_mean['VTRAC']-(grid.interp(ds_mean['TRAC'],'Y')*ds_vel['VVEL']))\n",
    "production = -dot_prod(q_pr_u_pr, q_pr_v_pr, q_mean_gradx, q_mean_grady, grid, ds_mean['TRAC'])\n",
    "production\n",
    "\n",
    "# production_x = (ds_mean['UTRAC']-(grid.interp(ds_mean['TRAC'],'X')*ds_vel['UVEL']))*q_mean_gradx\n",
    "# production_y = (ds_mean['VTRAC']-(grid.interp(ds_mean['TRAC'],'Y')*ds_vel['VVEL']))*q_mean_grady\n",
    "# production_x_int = production_x*_get_dy(production_x, grid._ds)\n",
    "# production_y_int = production_y*_get_dx(production_y, grid._ds)\n",
    "# production_int = xr.DataArray(production_x_int.data+production_y_int.data,\n",
    "#                              coords=ds_mean['TRAC'].coords, dims=ds_mean['TRAC'].dims)\n",
    "# production = production_int/_get_area(production_int, grid._ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (tracer_no: 2, time: 292, j: 1600, i: 3600)>\n",
       "dask.array<shape=(2, 292, 1600, 3600), dtype=float64, chunksize=(1, 1, 1600, 3600)>\n",
       "Coordinates:\n",
       "  * tracer_no  (tracer_no) int64 1 2\n",
       "  * i          (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "  * j          (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "    XC         (j, i) float32 0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 ...\n",
       "    YC         (j, i) float32 -79.95 -79.95 -79.95 -79.95 -79.95 -79.95 ...\n",
       "    rA         (j, i) float32 2.15699e+07 2.15699e+07 2.15699e+07 ...\n",
       "    Depth      (j, i) float32 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
       "    hFacC      (j, i) float32 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
       "    iter       (time) int64 2880 5760 8640 11520 14400 17280 20160 23040 ...\n",
       "  * time       (time) int64 2592000 5184000 7776000 10368000 12960000 ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance tendency\n",
    "q_pr_sq_snap = (ds_snap['TRACSQ']-(ds_snap['TRAC']**2))/2\n",
    "dt = ds_snap['TRACSQ'].time[0:2].diff('time').data\n",
    "tendency = (q_pr_sq_snap/2).diff('time')/dt\n",
    "tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (tracer_no: 2, time: 292, j: 1600, i: 3600)>\n",
       "dask.array<shape=(2, 292, 1600, 3600), dtype=float32, chunksize=(1, 1, 1600, 3600)>\n",
       "Coordinates:\n",
       "  * tracer_no  (tracer_no) int64 1 2\n",
       "  * time       (time) int64 2592000 5184000 7776000 10368000 12960000 ...\n",
       "  * j          (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "  * i          (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "    XC         (j, i) float32 0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 ...\n",
       "    YC         (j, i) float32 -79.95 -79.95 -79.95 -79.95 -79.95 -79.95 ...\n",
       "    rA         (j, i) float32 2.15699e+07 2.15699e+07 2.15699e+07 ...\n",
       "    Depth      (j, i) float32 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
       "    hFacC      (j, i) float32 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance diffusion\n",
    "diffusion = laplacian(variance_mean*kappa,grid)\n",
    "diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (tracer_no: 2, time: 292, j: 1600, i: 3600)>\n",
       "dask.array<shape=(2, 292, 1600, 3600), dtype=float32, chunksize=(1, 1, 1600, 3600)>\n",
       "Coordinates:\n",
       "  * tracer_no  (tracer_no) int64 1 2\n",
       "  * time       (time) int64 2592000 5184000 7776000 10368000 12960000 ...\n",
       "  * j          (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "  * i          (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative way to compute diffusion\n",
    "variance_gradx, variance_grady = gradient(variance_mean, grid)\n",
    "variance_gradxx,_ = gradient(grid.interp(variance_gradx, 'X'), grid)\n",
    "_,variance_gradyy = gradient(grid.interp(variance_grady, 'Y'), grid)\n",
    "diffusion_alt = kappa*(grid.interp(variance_gradxx, 'X')+\n",
    "                       grid.interp(variance_gradyy, 'Y'))\n",
    "diffusion_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of all terms\n",
    "all_sum = diffusion+advection+destruction+production\n",
    "part_sum = destruction+production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (concat_dim: 7, tracer_no: 2, time: 292, j: 1600, i: 3600)>\n",
       "dask.array<shape=(7, 2, 292, 1600, 3600), dtype=float64, chunksize=(1, 1, 1, 1600, 3600)>\n",
       "Coordinates:\n",
       "  * concat_dim  (concat_dim) <U11 'tendency' 'diffusion' 'advection' ...\n",
       "Dimensions without coordinates: tracer_no, time, j, i"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick order of magnitude sanity check.\n",
    "combo = xr.concat([tendency.drop(tendency.coords),\n",
    "                   diffusion.drop(diffusion.coords),\n",
    "                   advection.drop(advection.coords),\n",
    "                   destruction.drop(destruction.coords),\n",
    "                   production.drop(production.coords),\n",
    "                   all_sum.drop(all_sum.coords),\n",
    "                   part_sum.drop(part_sum.coords)],\n",
    "                dim=['tendency',\n",
    "                     'diffusion',\n",
    "                     'advection',\n",
    "                     'destruction',\n",
    "                     'production',\n",
    "                     'sum',\n",
    "                     'part_sum'])\n",
    "combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combo.isel(time=slice(30,40)).mean('time').plot(col='concat_dim',row='tracer_no',robust=True, norm=mpl.colors.SymLogNorm(1e-16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combo.mean('time').plot(col='concat_dim',row='tracer_no',robust=True, norm=mpl.colors.SymLogNorm(1e-18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.isel(concat_dim=[0, 3, 4, 6]).mean('time').plot(col='concat_dim',\n",
    "                                                      row='tracer_no',robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
