{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate raw AVISO velocities onto MITgcm grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import os.path\n",
    "import matplotlib as mpl\n",
    "from xmitgcm import open_mdsdataset\n",
    "from xarrayutils.numpy_utils import interp_map_regular_grid\n",
    "from mitgcm_surface_tracer.utils import readbin, writebin\n",
    "from mitgcm_surface_tracer.velocity_processing import combine_validmask, validmask_aviso\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validmask_aviso(da_u, da_v):\n",
    "    validmask_aviso_u = np.all(~np.isnan(da_u),\n",
    "                               axis=da_u.get_axis_num('time'))\n",
    "    validmask_aviso_v = np.all(~np.isnan(da_v),\n",
    "                               axis=da_v.get_axis_num('time'))\n",
    "\n",
    "    if np.logical_xor(validmask_aviso_u, validmask_aviso_v).any():\n",
    "        raise RuntimeWarning('U and V validmask are not equal')\n",
    "\n",
    "    validmask_aviso = np.logical_and(validmask_aviso_u, validmask_aviso_v)\n",
    "    return validmask_aviso\n",
    "\n",
    "\n",
    "def combine_validmask(data_dir, shape=None, debug=False):\n",
    "\n",
    "    fnames = []\n",
    "    for dirpath, dirnames, filenames in os.walk(data_dir):\n",
    "        for filename in [f for f in filenames if f == 'validmask.bin']:\n",
    "            print('found validmask at '+os.path.join(dirpath, filename))\n",
    "            fnames.append(os.path.join(dirpath, filename))\n",
    "    if debug:\n",
    "        print('data_dir', data_dir)\n",
    "        print(fnames)\n",
    "\n",
    "    if shape:\n",
    "        masks = np.array([readbin(f, shape) for f in fnames])\n",
    "    else:\n",
    "        raise RuntimeWarning('When shape is not given')\n",
    "\n",
    "    combo = np.all(np.stack(masks, axis=2), axis=2)\n",
    "\n",
    "    fpath = data_dir+'/validmask_combined.bin'\n",
    "    writebin(combo, fpath)\n",
    "    print('--- combined validmask written to '+fpath+' ---')\n",
    "\n",
    "\n",
    "def process_aviso(odir, gdir, ddir_dt, fid_dt,\n",
    "                  ddir_nrt=None, fid_nrt=None, interpolate=True):\n",
    "    \"\"\"read aviso files into xarray dataset, respecting 'seam' between\n",
    "    delayed-time\n",
    "    product and near-real time products\n",
    "\n",
    "    \"\"\"\n",
    "    grid = open_mdsdataset(gdir, iters=None)\n",
    "    ds_dt = xr.open_mfdataset(ddir_dt+'/'+fid_dt).drop(['nv', 'crs'])\n",
    "    if ddir_nrt is not None:\n",
    "        transition_date = ds_dt.time.isel(time=-1)\n",
    "        ds_nrt = xr.open_mfdataset(ddir_nrt+'/'+fid_nrt).drop(['nv', 'crs'])\n",
    "        ds = xr.concat((ds_dt,\n",
    "                        ds_nrt.isel(time=ds_nrt.time > transition_date)),\n",
    "                       dim='time')\n",
    "        # Test if time is continous\n",
    "        if np.any(ds.time.diff('time').data != ds.time.diff('time')[0].data):\n",
    "            print(ds.time)\n",
    "            raise RuntimeError('Time steps are not homogeneous. Likely missing \\\n",
    "            files between the dt and nrt products')\n",
    "    else:\n",
    "        ds = ds_dt\n",
    "        transition_date = ''\n",
    "    start_date = ds.time[0].data\n",
    "\n",
    "    # Write out the startdate and transition_date to textfile\n",
    "    f = open(odir+'/startdate.txt', 'w')\n",
    "    f.write(str(start_date))\n",
    "    f.close()\n",
    "    print('--- startdate written to '+odir+'/startdate.txt ---')\n",
    "\n",
    "    f = open(odir+'/transitiondate.txt', 'w')\n",
    "    f.write(str(transition_date))\n",
    "    f.close()\n",
    "    print('--- startdate written to '+odir+'/startdate.txt ---')\n",
    "\n",
    "    # create and save validmask\n",
    "    # validmask indicates values that were interpolated or filled\n",
    "    # and should be taken out for certain interpretations.\n",
    "    validmask = validmask_aviso(ds.u, ds.v)\n",
    "    validmask_mit = interp_map_regular_grid(validmask,\n",
    "                                            ds.u.lon.data,\n",
    "                                            ds.u.lat.data,\n",
    "                                            grid.XC.data,\n",
    "                                            grid.YC.data)\n",
    "    # fill the values between 0 and with 1 to exclude them from valid points.\n",
    "    validmask_mit[validmask_mit != 1] = 0\n",
    "    writebin(validmask_mit, odir+'/validmask.bin')\n",
    "    print('--- validmask written to '+odir+'/validmask.bin ---')\n",
    "\n",
    "    start_time = time.time()\n",
    "    for tt, ti in enumerate(ds.time.data):\n",
    "        u = ds.u.sel(time=ti).values\n",
    "        v = ds.v.sel(time=ti).values\n",
    "\n",
    "        # Velocities near the coast are padded with zeros\n",
    "        u[np.isnan(u)] = 0\n",
    "        v[np.isnan(v)] = 0\n",
    "\n",
    "        u_int = interp_map_regular_grid(u,\n",
    "                                        ds.u.lon.data,\n",
    "                                        ds.u.lat.data,\n",
    "                                        grid.XG.data,\n",
    "                                        grid.YC.data)\n",
    "        v_int = interp_map_regular_grid(v,\n",
    "                                        ds.v.lon.data,\n",
    "                                        ds.v.lat.data,\n",
    "                                        grid.XC.data,\n",
    "                                        grid.YG.data)\n",
    "\n",
    "        if np.any(np.isnan(u_int.flatten())):\n",
    "            raise RuntimeError('Nans detected in the u fields')\n",
    "        if np.any(np.isnan(v_int.flatten())):\n",
    "            raise RuntimeError('Nans detected in the v fields')\n",
    "\n",
    "        writebin(u_int, odir+'/uvel'+str(ti))\n",
    "        writebin(v_int, odir+'/vvel'+str(ti))\n",
    "\n",
    "        print(str(tt)+'/'+str(len(ds.time)))\n",
    "        print(str(ti))\n",
    "\n",
    "    print(\"--- Velocity Interpolation took %s seconds ---\"\n",
    "          % (time.time() - start_time))\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odir = \n",
    "gdir = \n",
    "ddir_dt = \n",
    "ddir_\n",
    "fid_dt = \n",
    "ddir_nrt = None\n",
    "fid_nrt=None\n",
    "\n",
    "process_aviso(odir, gdir, ddir_dt, fid_dt,ddir_nrt=None, fid_nrt=None, interpolate=True):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
